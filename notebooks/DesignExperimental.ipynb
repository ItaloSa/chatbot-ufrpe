{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DesignExperimental.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2y04wqvuLx0",
        "colab_type": "text"
      },
      "source": [
        "# Dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRDn-F3suKnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "database = [\n",
        "    {\"classe\": \"horario\", \"sentencas\": (\n",
        "        \"qual vai ser o horário de robótica?\",\n",
        "        \"Alguém que faz IC com Abner(circuitos) tem como perguntar a ele qual o horário?\",\n",
        "        \"Alguém sabe o horário das disciplinas optativas?\",\n",
        "        \"Robótica esse período, foi em quais horários?\",\n",
        "        \"Qual horário de calculo 2 nesse período?\",\n",
        "        \"Qual o horário de IP2\", \"Que horas começa a aula de TC?\"\n",
        "    )},\n",
        "    {\"classe\": \"duvida\",\"sentencas\": (\n",
        "        \"O que você pode fazer?\", \"O que você faz?\", \"Em que você pode me ajudar?\", \n",
        "        \"Me diga o que pode fazer\", \"Qual sua função?\", \"para que você serve?\", \"Do que você é capaz?\"\n",
        "    )},\n",
        "    {\"classe\": \"ementa\", \"sentencas\": (\n",
        "        \"Tem como enviar ementa da disciplina?\", \"Ementa de teoria\", \n",
        "        \"Qual a ementa de algoritmos\", \"Assunto da cadeira de algebra\", \n",
        "        \"Plano de aula de arquitetura\", \"Assunto das aulas de compiladores\"\n",
        "    )},\n",
        "    {\"classe\": \"pre_requisito\", \"sentencas\": (\n",
        "        \"Sabe se precisa de algum pré requisito para IA?\", \"SO tem pre requisito?\", \n",
        "        \"Qual pre-requisito para prog2\", \"Lista de pre requisitos para projetão\",\n",
        "        \"quais a cadeiras que preciso ter pago para pagar Sistemas Operacionais\", \n",
        "        \"Quais os pre-requisitos\", \"o que tenho que pagar antes de banco de dados?\"\n",
        "    )},\n",
        "    {\"classe\": \"carga_horária\", \"sentencas\": (\n",
        "        \"Sem carga horária não serve.\",\n",
        "        \"Ele disse que cumpriu a carga horária\",\n",
        "        \"Se der certificado e lá tiver escrito a carga horária\",\n",
        "        \"Qual a carga horária\", \"Quanto tempo\", \"Qual a ch?\", \"Quantas horas\"\n",
        "    )},\n",
        "    {\"classe\": \"sala\", \"sentencas\": (\n",
        "        \"discreta I qual a sala?\",\n",
        "        \"Alguém sabe a sala de circuitos?\",\n",
        "        \"qual a sala de Prog2\", \"onde é a aula de calculo?\",\n",
        "    )},\n",
        "    {\"classe\": \"professor\", \"sentencas\": (\n",
        "        \"Quem ta dando discreta?\", \"qual professor de pensamento computacional\",\n",
        "        \"quem eh o professor de IP2\", \"quem dá matematica discreta\", \n",
        "        \"qual o professor de algebra\", \"qual o nome do professor de prog2\"\n",
        "    )},\n",
        "    {\"classe\": \"estagio\", \"sentencas\": (\n",
        "        \"Como funciona eso\", \"como cortar eso\", \"trabalho dispensa eso\", \"estagio corta eso\",\n",
        "        \"como posso dispensar ESO\", \"trabalho carteira asinada dispensa estágio\"\n",
        "    )}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q99N0bscCahR",
        "colab_type": "code",
        "outputId": "299e2d87-a914-4d73-c6f3-b649326119ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from random import shuffle\n",
        "def train_test_split(data, test_size=.3):\n",
        "    train = []\n",
        "    test = []\n",
        "    for classe in data:\n",
        "        s = list(classe['sentencas'])\n",
        "        shuffle(s)\n",
        "        train.append({'classe': classe['classe'], 'sentencas': s[int(len(classe['sentencas'])*test_size):]})\n",
        "        test.append({'classe': classe['classe'], 'sentencas': s[0:int(len(classe['sentencas'])*test_size)]})\n",
        "    return train, test\n",
        "\n",
        "training_data, test_data = train_test_split(database)\n",
        "\n",
        "classes = list(set([a['classe'] for a in training_data]))\n",
        "classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pre_requisito',\n",
              " 'sala',\n",
              " 'duvida',\n",
              " 'horario',\n",
              " 'estagio',\n",
              " 'ementa',\n",
              " 'carga_horária',\n",
              " 'professor']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "785LBzq6XAHt",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes + Bag of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3VZYrqkW6PM",
        "colab_type": "code",
        "outputId": "0ea0d536-ec3a-4744-d069-9bf6d1a6bdcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l58pdysBZOKF",
        "colab_type": "code",
        "outputId": "043c720b-e925-4ff7-f803-5ab85454166a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "corpus_words = {}\n",
        "class_words = {}\n",
        "\n",
        "for c in classes:\n",
        "    class_words[c] = []\n",
        "\n",
        "for data in training_data:\n",
        "    for sentence in data['sentencas']:\n",
        "        for word in nltk.word_tokenize(sentence):\n",
        "            if word not in [\"?\", \"'s\"]:\n",
        "                stemmed_word = stemmer.stem(word.lower())\n",
        "                if stemmed_word not in corpus_words:\n",
        "                    corpus_words[stemmed_word] = 1\n",
        "                else:\n",
        "                    corpus_words[stemmed_word] += 1\n",
        "                class_words[data['classe']].extend([stemmed_word])\n",
        "\n",
        "print (\"Corpus words and counts: %s \\n\" % corpus_words)\n",
        "print (\"Class words: %s\" % class_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corpus words and counts: {'qual': 10, 'vai': 1, 'ser': 1, 'o': 7, 'horário': 4, 'de': 17, 'robótic': 2, 'que': 9, 'hora': 1, 'começ': 1, 'a': 9, 'aul': 2, 'tc': 1, 'ip2': 2, 'calculo': 1, '2': 1, 'ness': 1, 'período': 2, 'ess': 1, ',': 1, 'foi': 1, 'em': 1, 'qua': 3, 'você': 3, 'pod': 2, 'faz': 2, 'me': 1, 'dig': 1, 'par': 3, 'serv': 2, 'do': 1, 'é': 1, 'capaz': 1, 'sua': 1, 'função': 1, 'plano': 1, 'arquitetur': 1, 'assunto': 1, 'das': 1, 'aula': 1, 'compilad': 1, 'ement': 3, 'algoritmo': 1, 'tem': 2, 'como': 3, 'envi': 1, 'da': 1, 'disciplin': 1, 'teor': 1, 'os': 1, 'pre-requisitos': 1, 'list': 1, 'pre': 2, 'requisito': 2, 'projetão': 1, 'tenho': 1, 'pag': 2, 'ant': 1, 'banco': 1, 'dado': 1, 'cadeira': 1, 'preciso': 1, 'ter': 1, 'pago': 1, 'sistema': 1, 'operaciona': 1, 'so': 1, 'el': 1, 'diss': 1, 'cumpriu': 1, 'carg': 3, 'horár': 3, 'se': 1, 'der': 1, 'certificado': 1, 'e': 1, 'lá': 1, 'tiv': 1, 'escrito': 1, 'ch': 1, 'sem': 1, 'não': 1, '.': 1, 'quanto': 1, 'tempo': 1, 'sal': 3, 'prog2': 1, 'discret': 3, 'i': 1, 'alguém': 1, 'sab': 1, 'circuito': 1, 'quem': 3, 'eh': 1, 'profess': 3, 'ta': 1, 'dando': 1, 'dá': 1, 'matematic': 1, 'pensamento': 1, 'computac': 1, 'algebr': 1, 'trabalho': 2, 'carteir': 1, 'asinad': 1, 'dispens': 3, 'estágio': 1, 'estagio': 1, 'cort': 1, 'eso': 4, 'posso': 1, 'funcion': 1} \n",
            "\n",
            "Class words: {'pre_requisito': ['qua', 'os', 'pre-requisitos', 'list', 'de', 'pre', 'requisito', 'par', 'projetão', 'o', 'que', 'tenho', 'que', 'pag', 'ant', 'de', 'banco', 'de', 'dado', 'qua', 'a', 'cadeira', 'que', 'preciso', 'ter', 'pago', 'par', 'pag', 'sistema', 'operaciona', 'so', 'tem', 'pre', 'requisito'], 'sala': ['qual', 'a', 'sal', 'de', 'prog2', 'discret', 'i', 'qual', 'a', 'sal', 'alguém', 'sab', 'a', 'sal', 'de', 'circuito'], 'duvida': ['o', 'que', 'você', 'pod', 'faz', 'me', 'dig', 'o', 'que', 'pod', 'faz', 'par', 'que', 'você', 'serv', 'do', 'que', 'você', 'é', 'capaz', 'qual', 'sua', 'função'], 'horario': ['qual', 'vai', 'ser', 'o', 'horário', 'de', 'robótic', 'que', 'hora', 'começ', 'a', 'aul', 'de', 'tc', 'qual', 'o', 'horário', 'de', 'ip2', 'qual', 'horário', 'de', 'calculo', '2', 'ness', 'período', 'robótic', 'ess', 'período', ',', 'foi', 'em', 'qua', 'horário'], 'estagio': ['trabalho', 'carteir', 'asinad', 'dispens', 'estágio', 'estagio', 'cort', 'eso', 'como', 'posso', 'dispens', 'eso', 'trabalho', 'dispens', 'eso', 'como', 'funcion', 'eso'], 'ementa': ['plano', 'de', 'aul', 'de', 'arquitetur', 'assunto', 'das', 'aula', 'de', 'compilad', 'qual', 'a', 'ement', 'de', 'algoritmo', 'tem', 'como', 'envi', 'ement', 'da', 'disciplin', 'ement', 'de', 'teor'], 'carga_horária': ['el', 'diss', 'que', 'cumpriu', 'a', 'carg', 'horár', 'se', 'der', 'certificado', 'e', 'lá', 'tiv', 'escrito', 'a', 'carg', 'horár', 'qual', 'a', 'ch', 'sem', 'carg', 'horár', 'não', 'serv', '.', 'quanto', 'tempo'], 'professor': ['quem', 'eh', 'o', 'profess', 'de', 'ip2', 'quem', 'ta', 'dando', 'discret', 'quem', 'dá', 'matematic', 'discret', 'qual', 'profess', 'de', 'pensamento', 'computac', 'qual', 'o', 'profess', 'de', 'algebr']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxtDBeuMcI7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_class_score(sentence, class_name, show_details=True):\n",
        "    score = 0\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        if stemmer.stem(word.lower()) in class_words[class_name]:\n",
        "            score += 1\n",
        "            if show_details:\n",
        "                print (\"   match: %s\" % stemmer.stem(word.lower()))\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLHRPT4_cMuT",
        "colab_type": "code",
        "outputId": "83016922-db7b-4ca4-f569-1314e0b42b80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "sentence = \"Qual a sala de psicologia2?\"\n",
        "\n",
        "for c in class_words.keys():\n",
        "    print (\"Class: %s  Score: %s \\n\" % (c, calculate_class_score(sentence, c)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   match: a\n",
            "   match: de\n",
            "Class: pre_requisito  Score: 2 \n",
            "\n",
            "   match: qual\n",
            "   match: a\n",
            "   match: sal\n",
            "   match: de\n",
            "Class: sala  Score: 4 \n",
            "\n",
            "   match: qual\n",
            "Class: duvida  Score: 1 \n",
            "\n",
            "   match: qual\n",
            "   match: a\n",
            "   match: de\n",
            "Class: horario  Score: 3 \n",
            "\n",
            "Class: estagio  Score: 0 \n",
            "\n",
            "   match: qual\n",
            "   match: a\n",
            "   match: de\n",
            "Class: ementa  Score: 3 \n",
            "\n",
            "   match: qual\n",
            "   match: a\n",
            "Class: carga_horária  Score: 2 \n",
            "\n",
            "   match: qual\n",
            "   match: de\n",
            "Class: professor  Score: 2 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVA6xDaccsZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_class_score(sentence, class_name, show_details=True):\n",
        "    score = 0\n",
        "    for word in nltk.word_tokenize(sentence):\n",
        "        if stemmer.stem(word.lower()) in class_words[class_name]:\n",
        "            score += (1 / corpus_words[stemmer.stem(word.lower())])\n",
        "            if show_details:\n",
        "                print (\"   match: %s (%s)\" % (stemmer.stem(word.lower()), 1 / corpus_words[stemmer.stem(word.lower())]))\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boBjqoZncu65",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classify(sentence):\n",
        "    high_class = None\n",
        "    high_score = 0\n",
        "    for c in class_words.keys():\n",
        "        score = calculate_class_score(sentence, c, show_details=False)\n",
        "        if score > high_score:\n",
        "            high_class = c\n",
        "            high_score = score\n",
        "\n",
        "    return high_class, high_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0UEiub0c2Ag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_test = []\n",
        "for classe in test_data:\n",
        "    for sentenca in classe['sentencas']:\n",
        "        to_test.append((classe['classe'], sentenca))\n",
        "\n",
        "matriz = [[0 for c in range(len(classes))] for l in range(len(classes))]\n",
        "\n",
        "corretas, todas = 0, 0\n",
        "for label, sentence in to_test:\n",
        "    predict, confidence = classify(sentence)\n",
        "    matriz[classes.index(label)][classes.index(predict)] += 1\n",
        "\n",
        "import numpy as np\n",
        "matriz_transpose = np.transpose(matriz)\n",
        "TP, TN, FP, FN = 0, 0, 0, 0\n",
        "for l in range(len(matriz)):\n",
        "    TP += matriz[l][l]\n",
        "    TN += sum(np.diagonal(matriz)) - matriz[l][l]\n",
        "    FP += sum(matriz_transpose[l]) - matriz[l][l]\n",
        "    FN += sum(matriz[l]) - matriz[l][l]\n",
        "\n",
        "TP /= len(matriz)\n",
        "TN /= len(matriz)\n",
        "FP /= len(matriz)\n",
        "FN /= len(matriz)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACjaDqmmFSaW",
        "colab_type": "code",
        "outputId": "acd37fa7-3a39-4ba2-e42f-086a2549c4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acuracia = (TP + TN) / (TP + TN + FP + FN)\n",
        "recall = TP / (TP+FN)\n",
        "precisao =  TP / (TP+FP)\n",
        "fscore = 2*((precisao*recall)/(precisao + recall))\n",
        "print(f'Acurácia: {acuracia}, Recall: {recall}, Precisão: {precisao}, F-Score: {fscore}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acurácia: 0.7407407407407407, Recall: 0.4166666666666667, Precisão: 0.4166666666666667, F-Score: 0.4166666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c14Ddt2addCj",
        "colab_type": "text"
      },
      "source": [
        "# Keras + Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYlSaGlKejH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "%tensorflow_version 2.x\n",
        "!pip install ktrain"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRO0_Gn_djuv",
        "colab_type": "code",
        "outputId": "af18f531-e74c-4212-ddd8-6783b94ee0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import ktrain\n",
        "from ktrain import text\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using Keras version: 2.2.4-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DulKIwwm8ool",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test = [], [], [], []\n",
        "for classe in training_data:\n",
        "    for sentenca in classe['sentencas']:\n",
        "        y_train.append(classes.index(classe['classe']))\n",
        "        x_train.append(sentenca)\n",
        "\n",
        "for classe in test_data:\n",
        "    for sentenca in classe['sentencas']:\n",
        "        y_test.append(classes.index(classe['classe']))\n",
        "        x_test.append(sentenca)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV2JaJIiJ_ql",
        "colab_type": "code",
        "outputId": "4f29f91b-e6c9-4e34-bbdd-dc70cfc83835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "(x_train,  y_train), (x_test, y_test), preproc = text.texts_from_array(x_train=x_train, y_train=y_train,\n",
        "                                                                       x_test=x_test, y_test=y_test,\n",
        "                                                                       class_names=classes,                                                                       \n",
        "                                                                       preprocess_mode='bert',\n",
        "                                                                       lang='pt',\n",
        "                                                                       maxlen=350, \n",
        "                                                                       max_features=35000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task: text classification\n",
            "downloading pretrained BERT model (multi_cased_L-12_H-768_A-12.zip)...\n",
            "[██████████████████████████████████████████████████]\n",
            "extracting pretrained BERT model...\n",
            "done.\n",
            "\n",
            "cleanup downloaded zip...\n",
            "done.\n",
            "\n",
            "preprocessing train...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "preprocessing test...\n",
            "language: pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtD-e2MMNT0q",
        "colab_type": "code",
        "outputId": "8fe798ba-4e4b-4e58-c790-5f1a4ae233a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "model = text.text_classifier('bert', train_data=(x_train, y_train), preproc=preproc)\n",
        "learner = ktrain.get_learner(model, train_data=(x_train, y_train), batch_size=6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 350\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcM3x8CDOiAF",
        "colab_type": "code",
        "outputId": "9fe9ced5-51da-43f2-e13d-f826ee993e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "learner.fit_onecycle(2e-5, 4)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 2e-05...\n",
            "Train on 38 samples\n",
            "Epoch 1/4\n",
            "38/38 [==============================] - 188s 5s/sample - loss: 2.1168 - accuracy: 0.1579\n",
            "Epoch 2/4\n",
            "38/38 [==============================] - 160s 4s/sample - loss: 1.9198 - accuracy: 0.3158\n",
            "Epoch 3/4\n",
            "38/38 [==============================] - 163s 4s/sample - loss: 1.5590 - accuracy: 0.6579\n",
            "Epoch 4/4\n",
            "38/38 [==============================] - 161s 4s/sample - loss: 1.2053 - accuracy: 0.7632\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8fc2e67c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGMIpUlgO9gg",
        "colab_type": "code",
        "outputId": "dda6c19b-c29f-4db6-86b7-b1fa8b28e122",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "learner.validate(val_data=(x_test, y_test), class_names=classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "pre_requisito       1.00      1.00      1.00         2\n",
            "         sala       0.00      0.00      0.00         1\n",
            "       duvida       1.00      1.00      1.00         2\n",
            "      horario       0.67      1.00      0.80         2\n",
            "      estagio       0.50      1.00      0.67         1\n",
            "       ementa       1.00      1.00      1.00         1\n",
            "carga_horária       0.00      0.00      0.00         2\n",
            "    professor       0.50      1.00      0.67         1\n",
            "\n",
            "     accuracy                           0.75        12\n",
            "    macro avg       0.58      0.75      0.64        12\n",
            " weighted avg       0.61      0.75      0.66        12\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0],\n",
              "       [0, 0, 2, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 2, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hEE9O2cPIQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor = ktrain.get_predictor(learner.model, preproc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7eNhOjZP-51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor.save('predictor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmNdYKOlWHSH",
        "colab_type": "code",
        "outputId": "d594b650-8e4d-4bd3-d7c5-576dd7546f96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictor.predict(test_data[3]['sentencas'][0]), test_data[3]['sentencas'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('pre_requisito', 'Qual pre-requisito para prog2')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u7Fnea0cFdK",
        "colab_type": "code",
        "outputId": "aa31a656-2ce5-45ec-9e6f-40ab093a635c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9Rshk1IgIx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}