{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatbotTensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tz_Z58Be5wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tflearn\n",
        "import random\n",
        "import nltk\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "nltk.download('punkt')\n",
        "#..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIfrYQeGwI-K",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessando a base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsBvTUP93_om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "database = [\n",
        "    {\"classe\": \"horario\", \"sentencas\": (\n",
        "        \"qual vai ser o horário de robótica?\",\n",
        "        \"Alguém que faz IC com Abner(circuitos) tem como perguntar a ele qual o horário?\",\n",
        "        \"Alguém sabe o horário das disciplinas optativas?\",\n",
        "        \"Robótica esse período, foi em quais horários?\",\n",
        "        \"Qual horário de calculo 2 nesse período?\",\n",
        "        \"Qual o horário de IP2\", \"Que horas começa a aula de TC?\"\n",
        "    )},\n",
        "    {\"classe\": \"duvida\",\"sentencas\": (\n",
        "        \"O que você pode fazer?\", \"O que você faz?\", \"Em que você pode me ajudar?\", \n",
        "        \"Me diga o que pode fazer\", \"Qual sua função?\", \"para que você serve?\", \"Do que você é capaz?\"\n",
        "    )},\n",
        "    {\"classe\": \"ementa\", \"sentencas\": (\n",
        "        \"Tem como enviar ementa da disciplina?\", \"Ementa de teoria\", \n",
        "        \"Qual a ementa de algoritmos\", \"Assunto da cadeira de algebra\", \n",
        "        \"Plano de aula de arquitetura\", \"Assunto das aulas de compiladores\"\n",
        "    )},\n",
        "    {\"classe\": \"pre_requisito\", \"sentencas\": (\n",
        "        \"Sabe se precisa de algum pré requisito para IA?\", \"SO tem pre requisito?\", \n",
        "        \"Qual pre-requisito para prog2\", \"Lista de pre requisitos para projetão\",\n",
        "        \"quais a cadeiras que preciso ter pago para pagar Sistemas Operacionais\", \n",
        "        \"Quais os pre-requisitos\", \"o que tenho que pagar antes de banco de dados?\"\n",
        "    )},\n",
        "    {\"classe\": \"carga_horária\", \"sentencas\": (\n",
        "        \"Sem carga horária não serve.\",\n",
        "        \"Ele disse que cumpriu a carga horária\",\n",
        "        \"Se der certificado e lá tiver escrito a carga horária\",\n",
        "        \"Qual a carga horária\", \"Quanto tempo\", \"Qual a ch?\", \"Quantas horas\"\n",
        "    )},\n",
        "    {\"classe\": \"sala\", \"sentencas\": (\n",
        "        \"discreta I qual a sala?\",\n",
        "        \"Alguém sabe a sala de circuitos?\",\n",
        "        \"qual a sala de Prog2\", \"onde é a aula de calculo?\",\n",
        "    )},\n",
        "    {\"classe\": \"professor\", \"sentencas\": (\n",
        "        \"Quem ta dando discreta?\", \"qual professor de pensamento computacional\",\n",
        "        \"quem eh o professor de IP2\", \"quem dá matematica discreta\", \n",
        "        \"qual o professor de algebra\", \"qual o nome do professor de prog2\"\n",
        "    )},\n",
        "    {\"classe\": \"estagio\", \"sentencas\": (\n",
        "        \"Como funciona eso\", \"como cortar eso\", \"trabalho dispensa eso\", \"estagio corta eso\",\n",
        "        \"como posso dispensar ESO\", \"trabalho carteira asinada dispensa estágio\"\n",
        "    )}\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXzfBFIKyDMD",
        "colab_type": "text"
      },
      "source": [
        "# Importando as bibliotecas\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyDkrXL1fhoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_words = ['?', ':']\n",
        "\n",
        "for intent in database:\n",
        "    for pattern in intent['sentencas']:\n",
        "        # Tokenizando cada padrão\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        # Lista geral de padrões\n",
        "        words.extend(w)\n",
        "        # Lista de padrões com a classe correspondente\n",
        "        documents.append((w, intent['classe']))\n",
        "        # Adiciona a classe a lista de classes\n",
        "        if intent['classe'] not in classes:\n",
        "            classes.append(intent['classe'])\n",
        "\n",
        "# Aplicando stemming, palavras em minúsculo e ignorando as palavras definidas\n",
        "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
        "words = sorted(list(set(words)))\n",
        "\n",
        "# Removendo duplicatas\n",
        "classes = sorted(list(set(classes)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V64vkVrD7fLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To determine which version you're using:\n",
        "!pip show tensorflow\n",
        "\n",
        "# For the current version: \n",
        "!pip install --upgrade tensorflow\n",
        "\n",
        "# For a specific version:\n",
        "!pip install tensorflow==1.2\n",
        "\n",
        "# For the latest nightly build:\n",
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHqGPq4kwvmx",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnCluzg8gPZ0",
        "colab_type": "code",
        "outputId": "84b150c3-ec3f-40d5-8490-1261722cc93f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print (len(documents), \"documentos\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(words), \"unique stemmed words\", words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 documentos\n",
            "8 classes ['carga_horária', 'duvida', 'ementa', 'estagio', 'horario', 'pre_requisito', 'professor', 'sala']\n",
            "130 unique stemmed words ['(', ')', ',', '.', '2', 'a', 'abn', 'ajud', 'alg', 'algebr', 'algoritmo', 'alguém', 'ant', 'arquitetur', 'asinad', 'assunto', 'aul', 'aula', 'banco', 'cadeir', 'cadeira', 'calculo', 'capaz', 'carg', 'carteir', 'certificado', 'ch', 'circuito', 'com', 'começ', 'como', 'compilad', 'computac', 'cort', 'cumpriu', 'da', 'dado', 'dando', 'das', 'de', 'der', 'dig', 'disciplin', 'disciplina', 'discret', 'dispens', 'diss', 'do', 'dá', 'e', 'eh', 'el', 'em', 'ement', 'envi', 'escrito', 'eso', 'ess', 'estagio', 'estágio', 'faz', 'foi', 'funcion', 'função', 'hora', 'horár', 'horário', 'i', 'ia', 'ic', 'ip2', 'list', 'lá', 'matematic', 'me', 'ness', 'nom', 'não', 'o', 'ond', 'operaciona', 'optativa', 'os', 'pag', 'pago', 'par', 'pensamento', 'pergunt', 'período', 'plano', 'pod', 'posso', 'pre', 'pre-requisito', 'pre-requisitos', 'precis', 'preciso', 'profess', 'prog2', 'projetão', 'pré', 'qua', 'qual', 'quanta', 'quanto', 'que', 'quem', 'requisito', 'robótic', 'sab', 'sal', 'se', 'sem', 'ser', 'serv', 'sistema', 'so', 'sua', 'ta', 'tc', 'tem', 'tempo', 'tenho', 'teor', 'ter', 'tiv', 'trabalho', 'vai', 'você', 'é']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWWazDOVg9hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training = []\n",
        "output = []\n",
        "\n",
        "# Conjunto de trainamento, bloco de palavras para cada sentença\n",
        "for doc in documents:\n",
        "    # Iniciando o bloco\n",
        "    block = []\n",
        "    # Lista de palavras para cada padrão\n",
        "    pattern_words = doc[0]\n",
        "    # Aplica stemming para cada palavra\n",
        "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
        "    # Cria o bloco de palavras\n",
        "    for w in words:\n",
        "        block.append(1) if w in pattern_words else block.append(0)\n",
        "    # Saída é '0' para cada classe e '1' para a classe corrent\n",
        "    output_row = list([0] * len(classes))\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([block, output_row])\n",
        "\n",
        "# Embaralha as caracteristicas e converte para um array numpy\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "\n",
        "# Cria listas de treino\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YeHTGAo6wX1",
        "colab_type": "text"
      },
      "source": [
        "# Construindo a Rede Neural"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6576WmnhCS0",
        "colab_type": "code",
        "outputId": "79c774e0-d6dc-4db4-d61a-55ae04543f9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Parâmetros\n",
        "\n",
        "# Dados\n",
        "X = train_x\n",
        "Y = train_y\n",
        "# Número de neurônios por camada\n",
        "num_neurons_per_layer = [8, 8]\n",
        "# Número de camadas internas\n",
        "num_inner_layers = len(num_neurons_per_layer)\n",
        "# Tipo de ativação. Outros algoritmos: http://tflearn.org/activations/\n",
        "activation = 'softmax'\n",
        "# Número de epocas\n",
        "num_epoch = 1000\n",
        "\n",
        "# fim dos parâmetos \n",
        "\n",
        "# Limpa as definições\n",
        "tf.reset_default_graph()\n",
        "# Cria a camada de entrada\n",
        "net = tflearn.input_data(shape=[None, len(X[0])])\n",
        "# Cria as camadas internas\n",
        "for l in range(num_inner_layers):\n",
        "    net = tflearn.fully_connected(net, num_neurons_per_layer[l])\n",
        "# Cria a camada de saída\n",
        "net = tflearn.fully_connected(net, len(Y[0]), activation=activation)\n",
        "# aplica regressão\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "# Define o modelo e configura o tensorboard\n",
        "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
        "# Começa o treinamento (apply gradient descent algorithm)\n",
        "model.fit(X, Y, n_epoch=num_epoch, batch_size=8, show_metric=True)\n",
        "model.save('model.tflearn')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 6999  | total loss: \u001b[1m\u001b[32m0.51336\u001b[0m\u001b[0m | time: 0.024s\n",
            "| Adam | epoch: 1000 | loss: 0.51336 - acc: 0.9307 -- iter: 48/50\n",
            "Training Step: 7000  | total loss: \u001b[1m\u001b[32m0.46668\u001b[0m\u001b[0m | time: 0.028s\n",
            "| Adam | epoch: 1000 | loss: 0.46668 - acc: 0.9376 -- iter: 50/50\n",
            "--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDb3zrZQzbkh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Limpa as definições\n",
        "tf.reset_default_graph()\n",
        "# Cria a camada de entrada\n",
        "net = tflearn.input_data(shape=[None, len(X[0])])\n",
        "# Cria as camadas internas\n",
        "for l in range(num_inner_layers):\n",
        "    net = tflearn.fully_connected(net, num_neurons_per_layer[l])\n",
        "# Cria a camada de saída\n",
        "net = tflearn.fully_connected(net, len(Y[0]), activation=activation)\n",
        "# aplica regressão\n",
        "net = tflearn.regression(net)\n",
        "\n",
        "# Define o modelo e configura o tensorboard\n",
        "model2 = tflearn.DNN(net)\n",
        "\n",
        "model2.load('./model.tflearn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8K4pR7O5_Zmu",
        "colab_type": "text"
      },
      "source": [
        "# Salva os dados de treino"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5WJaNTuhLMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump( {'words':words, 'classes':classes, 'database': database, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxcqA7vU_yin",
        "colab_type": "text"
      },
      "source": [
        "# Funções para tratar o input do usuário"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dFcAQ47hPN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "    # Tokeniza o padrão\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # Aplica stemming para cada palavra\n",
        "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "\n",
        "# Retorna um array representando a sentença em: 0 or 1 para \n",
        "# cada palavra do bloco (words) que existe na sentença\n",
        "def bow(sentence, words, show_details=False):\n",
        "    # Tokeniza o padrão\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # Inicializa o bloco de palavras\n",
        "    block = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,w in enumerate(words):\n",
        "            if w == s: \n",
        "                block[i] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in block: %s\" % w)\n",
        "    return(np.array(block))\n",
        "\n",
        "# Recebe a intenção e um limiar para filtrar as predições\n",
        "# Retorna uma lista com a probabilidade de cada intenção\n",
        "def get_prob_intentions(sentence, threshold=0.6):\n",
        "    treated = bow(sentence, words)\n",
        "    prediction = model.predict([treated]).flatten()\n",
        "    sorted_intent_predict = sorted(zip(prediction, classes), key=lambda e: e[0], reverse=True)\n",
        "    return list(filter(lambda e: e[0] > threshold, sorted_intent_predict))\n",
        "\n",
        "# Busca no banco as respostas para uma determinada intenção\n",
        "def get_responses_from_database(database, intention):\n",
        "    obj = {}\n",
        "    for e in database:\n",
        "        if e['tag'] == intention:\n",
        "            return e['responses']\n",
        "    return []\n",
        "\n",
        "from random import choice\n",
        "# Retorna uma resposta baseado na intenção\n",
        "def get_response(database, sentence):\n",
        "    prob_intentions = get_prob_intentions(sentence)\n",
        "    if len(prob_intentions) == 0: return DEFAULT_RESPONSE\n",
        "    highest = prob_intentions[0]\n",
        "    confidence, intention = highest\n",
        "    responses = get_responses_from_database(database, intention)\n",
        "    return choice(responses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uFLNc1gwLA8",
        "colab_type": "text"
      },
      "source": [
        "# Testando o bot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqefLbnPvlsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bot_name = 'Bot'\n",
        "print('Fale tchau para sair!\\n')\n",
        "while True:\n",
        "    pergunta = input('Você: ')\n",
        "    if pergunta.lower() == 'tchau':\n",
        "        break\n",
        "    print(f'{bot_name}: {get_response(database, pergunta)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojpCOdHK8E-V",
        "colab_type": "code",
        "outputId": "23762c60-b241-4c5c-cb5d-2b7a5bac5c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}